from sklearn.metrics import make_scorer, f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score


def train_random_forest(X_train, y_train):
    rf = RandomForestClassifier(
    random_state=42,
    n_jobs=-1
    )
    param_grid = {
        "n_estimators":[100,200,300],
        "max_depth" : [None, 4, 5, 6],
        "min_samples_split" :[2,3,5],
        "min_samples_leaf": [1,2,5],
        "criterion" : ['gini', 'entropy']
    }
    scorer = make_scorer(f1_score)
    grid_search = GridSearchCV(
        estimator=rf,
        param_grid=param_grid,
        scoring=scorer,
        cv=5,
        verbose = 2,
        n_jobs=-1
    )
    grid_search.fit(X_train, y_train)
    return grid_search


def evaluate_model(model, X_test_scaled, y_test, model_name):
    preds = model.predict(X_test_scaled)
    
    accuracy = accuracy_score(y_test, preds)
    score = classification_report(y_test, preds)
    
    print(f"\n{model_name} Performance: ")
    print(f"Accuracy : {accuracy:.2f}")
    print(f"Score : {score}")
    